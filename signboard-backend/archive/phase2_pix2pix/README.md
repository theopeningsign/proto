# 📁 Phase 2 - Pix2Pix 시도 기록

## 📅 개발 기간
**2025.01.05 - 2025.01.06 (2일)**

## 🎯 원래 목적
Phase 1 CG 간판을 실사처럼 변환하는 모델 개발

---

## 🔧 개발한 것들

### **핵심 파일들**
- **`signboard_pair_tool.py`**: CG-실사 페어 생성 GUI 도구
- **`generate_pairs.py`**: 페어 생성 로직 및 유틸리티
- **`pix2pix_training.ipynb`**: Colab 학습 노트북
- **`COLAB_SETUP_GUIDE.md`**: 설치 및 설정 가이드
- **`COLAB_FIX.md`**: 발생한 오류들 해결 기록

### **데이터 구조**
```
phase2_data/
├── real_photos/           # 원본 실사 간판 사진들
│   ├── channel/          # 채널간판 (금속)
│   ├── flex/             # 플렉스간판 
│   ├── scasi/            # 스카시간판
│   └── labels.json       # 라벨링 데이터
├── cropped_photos/        # 크롭된 간판 이미지들 (512x512)
├── paired_data/          # pix2pix 학습용 페어 데이터
│   ├── train/
│   │   ├── input/        # CG 간판 (Phase 1 출력)
│   │   └── target/       # 실사 간판 (크롭된 사진)
│   └── test/
└── pairs_metadata.json   # 페어 메타데이터
```

---

## ✅ 성공한 부분들

### **1. 데이터 파이프라인 완성** 🎯
- **실사 사진 크롭**: 간판 부분만 정확하게 512x512로 추출
- **CG-실사 페어링**: 같은 텍스트의 CG와 실사 이미지 자동 매칭
- **자동 Train/Test 분할**: 8:2 비율로 자동 분할
- **메타데이터 관리**: 색상, 텍스트, 간판 타입 정보 저장

### **2. GUI 도구 완성** 🖥️
- **직관적인 인터페이스**: 4개 탭으로 구성된 완전한 GUI
- **실시간 미리보기**: 생성된 페어 확인 및 수동 보정
- **색상 추출 자동화**: 실사에서 배경색/텍스트색 자동 추출
- **배치 처리**: 수십 개 이미지 일괄 처리

### **3. 기술적 성과** 🔧
- **정확한 크롭핑**: OpenCV 기반 정밀 이미지 처리
- **색상 분석**: v1, v2 두 가지 색상 추출 알고리즘
- **Phase 1 연동**: 기존 CG 렌더링 시스템과 완벽 통합
- **Colab 최적화**: GPU 활용한 클라우드 학습 환경

---

## ❌ 중단 이유

### **1. 이미지 분할 문제** 🚨
```
문제: pix2pix가 완전한 이미지를 좌우로 분할해서 처리
현상: "광안다찌" → "광안" | "다찌"로 나누어짐
시도: --dataset_mode aligned, --no_flip 등 다양한 옵션 테스트
결과: junyanz/pytorch-CycleGAN-and-pix2pix에서 해결 안됨
```

### **2. 데이터 페어링 문제** 🔄
```
문제: Train/Test 분할 시 random.shuffle()로 인한 페어 파괴
현상: "광안" CG → "다찌" 실사 잘못된 매칭
해결책: 셔플링 로직 수정 필요했으나...
```

### **3. 학습 불안정성** 📉
```
문제: Epoch 70 이후 품질 급격히 하락 (Loss 발산)
원인: Generator-Discriminator 불균형
해결: Early stopping 또는 하이퍼파라미터 재조정 필요
```

---

## 🎓 얻은 교훈들

### **기술적 교훈**
1. **pix2pix 한계**: aligned 모드가 생각만큼 안정적이지 않음
2. **데이터 품질**: 페어링 정확도가 학습 성공의 핵심
3. **학습 모니터링**: Loss 그래프 실시간 확인 필수
4. **GPU 메모리**: 4GB VRAM으로는 배치 사이즈 제한적

### **개발 프로세스 교훈**
1. **프로토타입 우선**: 작은 데이터셋으로 먼저 검증
2. **조기 발견**: 근본적 문제는 빨리 포기하고 대안 찾기
3. **도구 활용**: GUI 도구가 디버깅에 큰 도움
4. **문서화**: 시행착오 과정 상세 기록의 중요성

---

## 🚀 대안으로 전환한 이유

### **Stable Diffusion + ControlNet 선택**
```
장점:
✅ 이미지 분할 문제 없음 (ControlNet으로 정확한 제어)
✅ 로컬 GPU 활용 가능 (비용 절약)
✅ 더 높은 품질 잠재력
✅ 커뮤니티 지원 풍부
✅ 유연한 프롬프트 제어

단점:
❌ 처음부터 다시 구축
❌ 기존 작업 일부 폐기
❌ 새로운 학습 곡선
```

---

## 💾 보관된 데이터

### **재사용 가능한 자산들**
- **크롭된 실사 간판**: `cropped_photos/` (512x512 정품질)
- **라벨링 데이터**: 텍스트, 색상, 타입 정보
- **Phase 1 연동 로직**: SD에서도 활용 가능
- **색상 추출 알고리즘**: `extract_colors_v2()` 재사용

### **참고용 자료들**
- **GUI 설계**: 향후 SD 도구 개발 시 참고
- **배치 처리 로직**: 대용량 데이터 처리 노하우
- **Colab 설정**: 클라우드 GPU 활용 경험

---

## 📊 투자 대비 성과

### **시간 투입**
- **개발**: 총 16시간 (2일)
- **데이터 준비**: 8시간
- **GUI 개발**: 4시간  
- **Colab 설정**: 2시간
- **디버깅**: 2시간

### **얻은 가치**
- **데이터셋**: 고품질 CG-실사 페어 수십 개
- **도구**: 재사용 가능한 이미지 처리 파이프라인
- **노하우**: pix2pix 한계와 대안에 대한 깊은 이해
- **코드 자산**: 3,000+ 라인의 검증된 코드

### **결론**: "실패"가 아닌 "귀중한 탐색 과정" ✨

---

## 🔮 향후 활용 방안

### **Stable Diffusion에서 재활용**
1. **크롭 데이터**: ControlNet 학습 데이터로 활용
2. **색상 추출**: 프롬프트 생성 시 색상 정보 활용  
3. **GUI 패턴**: SD 도구 개발 시 UX 참고
4. **배치 처리**: SD 대용량 처리 시스템에 적용

### **나중에 재시도 가능성**
- **더 나은 pix2pix 구현체** 발견 시
- **pix2pix 문제 해결 방법** 찾을 시
- **하이브리드 접근**: SD + pix2pix 조합

---

## 📝 마무리

**2일의 pix2pix 도전이 실패로 끝났지만, 이 과정에서 얻은 데이터와 노하우는 Stable Diffusion 개발에 큰 도움이 될 것입니다.**

**특히 완성된 데이터 파이프라인과 GUI 도구는 그 자체로도 충분한 가치가 있으며, 향후 다양한 형태로 재활용될 수 있습니다.**

**"실패는 성공의 어머니"라는 말처럼, 이 경험이 더 나은 Phase 2 구현의 밑거름이 되길 바랍니다.** 🌱

---

**개발자:** AI Assistant + Human Collaboration  
**보관일:** 2025.01.06  
**다음 도전:** Stable Diffusion + ControlNet 🚀

